<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rails | BLog]]></title>
  <link href="http://bleonard.github.io/blog/categories/rails/atom.xml" rel="self"/>
  <link href="http://bleonard.github.io/"/>
  <updated>2017-04-14T15:13:13-07:00</updated>
  <id>http://bleonard.github.io/</id>
  <author>
    <name><![CDATA[Brian Leonard]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Architecture: Background Processing]]></title>
    <link href="http://bleonard.github.io/blog/2017/03/17/architecture-background-processing/"/>
    <updated>2017-03-17T00:00:00-07:00</updated>
    <id>http://bleonard.github.io/blog/2017/03/17/architecture-background-processing</id>
    <content type="html"><![CDATA[<p>So we have a bunch of <a href="/blog/2017/02/24/architecture-models/">models</a> and are doing stuff with them in <a href="/blog/2017/03/03/architecture-service-objects/">service objects</a>. The next thing we might need is to process some code in the background.</p>

<p>Not everything can be done inline from the API request. For example, we might need to geocode a user's postal code when they change it in their account. Or when an invoice is created, we want to charge it 24 hours later.</p>

<p>When working with background jobs, we default to the following practices:</p>

<ul>
<li>Workers are enqueued with a dictionary of inputs</li>
<li>These inputs should be used to fetch data from the source of truth</li>
<li>Workers know how to check if they still need to run</li>
<li>Locking schemes should protect parallel execution</li>
</ul>


<h3>Enqueue</h3>

<p>When we enqueue a worker, we have found that it's quite helpful to always use a dictionary (hash) of key/value pairs. <a href="https://github.com/resque/resque">Resque</a> and <a href="http://sidekiq.org/">Sidekiq</a> both take a list of arguments like <a href="https://github.com/mperham/sidekiq/wiki/Getting-Started">so</a>:</p>

<p>```ruby
class HardWorker
  include Sidekiq::Worker
  def perform(name, count)</p>

<pre><code># do something with name, count
</code></pre>

<p>  end
end</p>

<h1>enqueue</h1>

<p>HardWorker.perform_async('bob', 5)
```</p>

<p>This has proved to be problematic when adding new parameters or having optional parameters. For example, if we add a new (third) input parameter, there might be stuff in the queue with the old two. When the new code gets deployed, it will throw an 'invalid number of arguments' type of error. When using a hash, we can give it a default, fail gracefully, or do whatever we like on a class by class basis.</p>

<p>So to provide better change management and optional arguments, we always do it like so:</p>

<p>```ruby
class HardWorker
  include TResque::Worker
  inputs :name, :count</p>

<p>  def work</p>

<pre><code># do something with self.name, self.count
</code></pre>

<p>  end
end</p>

<h1>enqueue</h1>

<p>HardWorker.enqueue(name: 'bob', count: 5)
```</p>

<h3>Source of Truth</h3>

<p>Let's say we want to update a search index every time a user record is changed. We need to write their first name, last name, etc to <a href="https://www.elastic.co/">Elasticsearch</a>.</p>

<p>We could do something like this:</p>

<p>```ruby
class UserIndexWorker
  include TResque::Worker
  inputs :id, :first_name, :last_name, :etc</p>

<p>  def work</p>

<pre><code>Elasticsearch.index('users').write(id, id: id, first_name: first_name, last_name: last_name, etc: etc)
</code></pre>

<p>  end
end</p>

<h1>When user changes</h1>

<p>UserIndexWorker.enqueue(user.attributes.slice(:id, :first_name, :last_name, :etc))
```</p>

<p>This certainly would work, but is not considered best practice. It is better to be <a href="http://www.restapitutorial.com/lessons/idempotency.html">idempotent</a>. It writes everything that should ) by passing the minimal information to the background worker, who then looks up the source of truth. That way, if there is any delay between when it is enqueued and run, it will still send the correct information.</p>

<p>The better approach would look like this:</p>

<p>```ruby
class UserIndexWorker
  include TResque::Worker
  inputs :user_id</p>

<p>  def work</p>

<pre><code>Elasticsearch.index('users').write(user.attributes.slice(:id, :first_name, :last_name, :etc))
</code></pre>

<p>  end</p>

<p>  def user</p>

<pre><code>@user ||= User.find(user_id)
</code></pre>

<p>  end
end</p>

<h1>When user changes</h1>

<p>UserIndexWorker.enqueue(user_id: user.id)
```</p>

<p>In the same vein, the worker should be in charge of whether or not it needs to do anything in the first place. For example, we can enqueue a worker to run later about an <code>Invoice</code>. If, at that time, the payment is <code>Invoice</code> still should be charged, then charge it.</p>

<p>```ruby
class InvoiceChargeWorker
  include TResque::Worker
  inputs :invoice_id</p>

<p>  def work</p>

<pre><code>return unless needed?
invoice.charge!
</code></pre>

<p>  end</p>

<p>  def needed?</p>

<pre><code>invoice.pending?
</code></pre>

<p>  end</p>

<p>  def invoice</p>

<pre><code>@invoice ||= Invoice.find(invoice_id)
</code></pre>

<p>  end
end</p>

<h1>When invoice is created</h1>

<p>InvoiceChargeWorker.enqueue_at(24.hours.from_now, invoice_id: invoice.id)
```</p>

<p>This is another example of single source of truth. Even for jobs that are run immediately, this check is something we always put in place: return immediately if the worker is no longer relevant.</p>

<h3>Mutual Exclusion</h3>

<p>Let's say the <code>User</code> object can sometimes change a few times rapidly. The "source of truth" approach will make sure the right thing always gets indexed. So that's great. But it is pretty silly to index the same data twice or more times, right?</p>

<p>In this case, we add a queue lock. The effect is that if something is in the queue and waiting to be processed and you try to enqueue another one with the same inputs, then it will be a no-op. It looks like this:</p>

<p>```ruby
class UserIndexWorker
  include TResque::Worker
  inputs :user_id</p>

<p>  queue_lock :user_id
end
```</p>

<p>Another case that often arises is mutual exclusion for <em>runtime</em>. Maybe weird payment things happen to the payment service if two invoices for the same user are happening at the same time.</p>

<p>In this case, we add a worker lock. The effect is that if something is in the queue and about to start running and there is another running at that moment, then it will re-enqueue itself to run later. It looks like this:</p>

<p>```ruby
class InvoiceChargeWorker
  include TResque::Worker
  inputs :invoice_id</p>

<p>  worker_lock :to_id</p>

<p>  def work</p>

<pre><code>return unless needed?
invoice.charge!
</code></pre>

<p>  end</p>

<p>  def to_id</p>

<pre><code>invoice.to_id
</code></pre>

<p>  end</p>

<p>  def needed?</p>

<pre><code>invoice.pending?
</code></pre>

<p>  end</p>

<p>  def invoice</p>

<pre><code>@invoice ||= Invoice.find(invoice_id)
</code></pre>

<p>  end
end
```</p>

<p>For either type, you don't have to lock on all the attributes or can (as shown in the last example) use calculations. The namespace of the lock is the worker class name. You can also set the namespace to allow locking between different workers.</p>

<h3>Message Bus</h3>

<p>Our <a href="/blog/2015/04/02/queue-bus/">message bus</a> and our use of background processes have a lot in common. In fact, the message bus is built on top of the same background processing infrastructure. The question that arises is this: when should something be enqueued directly and when should it publish and respond to a bus subscription?</p>

<p>The first note is that you should <em>always be publishing</em> (ABP). It doesn't hurt anything to give (optional) visibility to other systems what is happening. Or use this as logging framework.</p>

<p>Just publishing, however, doesn't mean we have to use that to do work in the background. Be can bother publish and enqueue a background worker. We enqueue a worker when the work in the background is essential to the correct operation of the use case at hand.</p>

<p>One example to enqueue directly would be the geocoding worker I mentioned earlier: when the user gives a new postal code, figure out where that is. It's key to the account management system.</p>

<p>The search example I've been using might not actually be the best one because we would have the search system subscribed to changes in the account system. What I didn't show that the <code>enqueue</code> call might actually happen from within a subscription.</p>

<p><code>ruby
subscribe "user_changed" do |attributes|
  UserIndexWorker.enqueue(user_id: attributes['id'])
end
</code></p>

<p>So these two concepts can work together. Why not just index it right in the subscription, though? A primary reason might be to use some of the locking mechanisms as the bus does not have that. It also might be the case that the worker is enqueued from other locations and this keeps things DRY. The worker is also easier to unit test.</p>

<h3>TResque</h3>

<p>We use <a href="https://github.com/resque/resque">Resque</a> as a base foundation and built on top of it with an abstraction layer called <a href="https://github.com/taskrabbit/tresque">TResque</a>. That's TR (TaskRabbit) Resque. Get it? It puts all of these practices into place as well as adding and abstraction layer for the inevitable, but as yet unprioritized, move to <a href="http://sidekiq.org/">Sidekiq</a>.</p>

<p>I don't necessarily expect anyone to use this, but it doesn't hurt to make it available as an example of how we are using these tools.</p>

<p>You define a worker and enqueue things as show in the examples above. Then only layer left is around prioritization. You can give a queue name to a worker and then register what priority those workers are. If no queue is given, it is assumed to be the <code>default</code> queue.</p>

<p>```ruby
require 'tresque'</p>

<p>module Account
  class RegularWorker</p>

<pre><code>include ::TResque::Worker
# defaults to account_default queue
</code></pre>

<p>  end
end</p>

<p>module Account
  class RegularWorker</p>

<pre><code>include ::TResque::Worker
queue :refresh # lower priority account_refresh queue
</code></pre>

<p>  end
end</p>

<p>TResque.register("account") do
  queue :default, 100
  queue :refresh, -5000
end
```</p>

<p>Then when you run Resque, you can use these registrations to process the queues in the right order.</p>

<p>```ruby
require 'resque/tasks'
require 'resque_scheduler/tasks'
require "resque_bus/tasks"</p>

<p>namespace :resque do
  task :setup => [:environment] do</p>

<pre><code>require 'resque_scheduler'
require 'resque/scheduler'
require 'tresque'
</code></pre>

<p>  end</p>

<p>  task :queues => [:setup] do</p>

<pre><code>queues = ::TResque::Registry.queues
ENV["QUEUES"] = queues.join(",")
puts "TResque: #{ENV["QUEUES"]}"
</code></pre>

<p>  end
end</p>

<p>```</p>

<p><code>
  $ bundle exec rake resque:queues resque:work
  TResque: account_default, account_refresh
</code></p>

<p>This registration layer allows each of the systems (<a href="/blog/2014/02/11/rails-4-engines/">engines</a>) to work independently and still have centralized background processing.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Architecture: Surface Area]]></title>
    <link href="http://bleonard.github.io/blog/2017/03/10/architecture-surface-area/"/>
    <updated>2017-03-10T00:00:00-08:00</updated>
    <id>http://bleonard.github.io/blog/2017/03/10/architecture-surface-area</id>
    <content type="html"><![CDATA[<p>The last post in the <a href="https://www.taskrabbit.com">TaskRabbit</a> architecture series was about <a href="/blog/2017/03/03/architecture-service-objects/">service objects</a>. This an example of what I call minimizing "surface area" of the code.</p>

<p>Frankly, I might be using the term wrong. It seems possible "surface area" usually refers to API signature of some objects. What I'm talking about here is the following train of thought:</p>

<ul>
<li>I change or add a line of code</li>
<li>What did I just affect?</li>
</ul>


<p>The "surface area" is the other things I have to look over. It is the area that I have to make sure has appropriate test coverage. Having a large surface area is what slows down development teams. The goal is to minimize it.</p>

<h3>Service Objects</h3>

<p>So how does our use of service objects relate to this concept?</p>

<p>Let's say we have a new requirement that's applicable when a Tasker submits an invoice that modifies what gets saved. If I were to add the code to the <code>InvoiceJobOp</code> from the <a href="/blog/2017/03/03/architecture-service-objects/">previous article</a>, then it will only apply when the <code>Op</code> is run. If we were to do something in a <code>before_save</code> in the <code>Invoice</code> model, then it might accidentally kick in anytime an <code>Invoice</code> is changed.</p>

<p>That's a lot more tests and things to keep in our mind. If it is just in the <code>Op</code>, that is less of those kinds of debt, so adding in the <code>Op</code> is an example of minimizing the surface area of the change.</p>

<h3>Namespacing</h3>

<p>We went through a <a href="/blog/2015/10/06/v2-retrospective/">roundabout journey</a> to end up where were we are. Many of the changes were about surface area and trying to reduce it.</p>

<p>People like microservices and SOA because of this same principle. We tried it and that part of it worked out really well. There was just no way that a change in service A could affect service B. As <a href="/blog/2015/10/06/v2-retrospective/">discussed</a>, however, we ran into issues in other dimensions.</p>

<p>Our current use of <a href="/blog/2014/02/11/rails-4-engines/">engines</a> follows the same approach to achieve the same surface area effect. It is all about namespacing. Modifying the user management engine can not affect the marketplace engine. This allows us to proceed with more confidence when making such changes.</p>

<p>A particular aspect of our setup is that any given model is "owned" by only one engine. The rest of the engines are allowed to read from the database but they cannot write. This provides sanity and minimizes the surface area. For example, the validations only need to live in one spot. You also know that no other code can go rogue and start messing with the data by accident or otherwise.</p>

<h3>Bus</h3>

<p>Of course, the world isn't always cut and dry. Venn diagrams overlap. No abstraction or encapsulation is perfect. The seams in namespacing show up when something that happens in one service (engine) needs to affect something in another one.</p>

<p>For example, we were so happy just a few paragraphs ago that changes to the user management engine do not affect the marketplace engine. That is true and it is great. There is no direct effect from the code. However, as they tend to do, these pesky functional requirements always mess up perfect plans for the code. In this case, when a user changes their first name (in the account engine), the marketplace engine might need to update some data in <a href="https://www.elastic.co/">Elasticsearch</a>.</p>

<p>We use a <a href="/blog/2015/04/02/queue-bus/">message bus</a> to observe changes like this and react as appropriate.</p>

<p>```ruby</p>

<h1>Whenever the user changes</h1>

<p>subscribe 'user_may_have_changed', bus_observer_touched: 'user' do |attributes|
  # update the profile in ElasticSearch
  ProfileStoreWorker.enqueue(user_id: attributes['id'])
end
```</p>

<p>An important note here is that <code>ProfileStoreWorker</code> is <a href="http://www.restapitutorial.com/lessons/idempotency.html">idempotent</a>. It writes everything that should go in Elasticsearch every time. This technique reduces surface area by not depending on this single event and its contents, but rather only as a trigger.</p>

<p>One might say that these subscriptions are just as coupled as doing everything all in one spot. I see that point because, of course, the same things end up happening. However, we have this technique to be better for a few reasons.</p>

<ul>
<li>The trigger code (in the account engine) does not need to know about the rest of the system. It can mind its own business.</li>
<li>The subscribing code (in the marketplace engine) can be self-contained instead of being mixed up in the trigger code path.</li>
<li>Many different code paths might necessitate the <code>ProfileStoreWorker</code> to run. By decoupling it, we actually save complexity in many code paths.</li>
</ul>


<h3>Summary</h3>

<p>In code, developers tend to weave a tangled web wherein seemingly innocuous changes have far-reaching effects. We have been able to create more stable and agile code by considering the "surface area" of a change and minimizing it through some encapsulation and decoupling techniques.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Architecture: Service Objects]]></title>
    <link href="http://bleonard.github.io/blog/2017/03/03/architecture-service-objects/"/>
    <updated>2017-03-03T00:00:00-08:00</updated>
    <id>http://bleonard.github.io/blog/2017/03/03/architecture-service-objects</id>
    <content type="html"><![CDATA[<p>This is the second post in what is now indisputably a "series" of articles about how we build things at <a href="https://www.taskrabbit.com">TaskRabbit</a>. Over time, we/I have internalized all kinds of lessons and patterns and are trying to take the time to write some of the key things down.</p>

<p>Building upwards from the <a href="/blog/2017/02/24/architecture-models/">last article about models</a>, let's talk about how we use them. The models represent rows in the database in the <a href="http://guides.rubyonrails.org/active_record_basics.html">Rails ORM</a>. What code is deciding what to put in those rows and which ones should be created, etc? In our architecture, this role is filled by <a href="https://www.netguru.co/blog/service-objects-in-rails-will-help">service objects</a>.</p>

<p>Overall, we default to the following rules when using models in our system:</p>

<ul>
<li>Models contain data/state validations and methods tied directly to them</li>
<li>Models are manipulated by service objects that reflect the user experience</li>
</ul>


<h3>Something has to be fat</h3>

<p>In the beginning, there was <a href="http://ideum.com/2006/07/05/102/">Rails</a> and we saw that it was good. The world was optimized around the CRUD/REST use cases. Controllers had <code>update_attributes</code> and such. When there was more logic/nuance, it was put there in the controller (or the view).</p>

<p>There was a backlash of sorts against that and the new paradigm was <a href="http://weblog.jamisbuck.org/2006/10/18/skinny-controller-fat-model">"Fat model, skinny controller"</a>. The controllers were simple and emphasized workflow instead of business logic. Views were simpler. That stuff was put in the models. Model code was easier to reuse.</p>

<p>Thus arose the great <a href="http://blog.codeclimate.com/blog/2012/10/17/7-ways-to-decompose-fat-activerecord-models/">"God Model"</a> issue. Fat is one thing, but we had some seriously obese models. Things like <code>User</code> and <code>Task</code> simply had too much going on. We could put stuff in mixins/concerns but that didn't change the fact that there was tons of code that all could be subtly interacting with each other.</p>

<p>Business logic has to go somewhere. For us, that somewhere is in service objects.</p>

<h3>Operations</h3>

<p>In our architecture, we call them "Operations" and they extend a class called <code>Backend::Op</code>. This more or less uses the <a href="https://github.com/mnelson/subroutine">subroutine</a> gem.</p>

<p>Much can be read about what it means to be a service object, but here is my very scientific (Rails-specific) definition.</p>

<ul>
<li>Includes <code>ActiveModel</code> stuff like <code>Naming</code>, <code>Validations</code>, and <code>Callbacks</code></li>
<li>Allows declaration of what fields (input parameters) it uses</li>
<li>Reflects an action in the system like "sign up a user" or "invoice a job"</li>
<li>Does whatever it needs to do to accomplish the action when asked including updating or creating one or more models</li>
</ul>


<p>Here's a simplified example:</p>

<p>```ruby
class InvoiceJobOp &lt; ::Backend::Op
  include Mixins::AtomicOperation # all in same transaction</p>

<p>  field :hours
  field :job_id</p>

<p>  validates :job_id, presence: true
  validate  :validate_hour       # hours given
  validate  :validate_assignment # tasker is assigned
  # ... other checks</p>

<p>  def perform</p>

<pre><code>create_invoice!    # record hours and such
generate_payment!  # pending payment transaction
appointment_done!  # note that appointment completed

if ongoing?
  schedule_next_appointment! # schedule next if more
else
  complete_assignment!       # otherwise, no more
end

enqueue_background_workers!  # follow up later on stuff
</code></pre>

<p>  end
end</p>

<p>```</p>

<h3>No Side Effects</h3>

<p>When we followed the "Fat Model" pattern, we got what we wanted. This was usually methods in one of the models. Sometimes there were callbacks added. These were the most dangerous because they were happening on every <code>save</code>. Often, this added unnecessary side effects.</p>

<p>With the service object approach, it is very clear what is happening for the action at hand. When you "invoice a job," you create the invoice, generate the payment, mark the appointment done, schedule the next appointment, and enqueue some background workers.</p>

<p>This certainty leads to less technical and product debt. When something new needs to be added to this action, it's very clear where it goes.</p>

<h3>Errors</h3>

<p>Our <code>Op</code> class above does several model manipulations to the related invoices, appointments, etc. Each some of these does a <code>save</code> to something. Those <code>save</code> calls could raise errors. If any of those raise an error, then the <code>Op</code> itself will inherit it and it will be available on the <code>op.errors</code> method just like a normal <code>ActiveRecord</code> object.</p>

<p>This also allows chaining of operations. If there was a <code>ScheduleAppointmentOp</code> class, it could be used in the above <code>schedule_next_appointment!</code> method. If it raised an error, it would propagate to the <code>InvoiceJobOp</code>.</p>

<h3>Controllers</h3>

<p>Generally speaking, we have one <code>Op</code> per controller action that declares what it expects and manipulates the backend data as needed.</p>

<p>Here is a typical example from one of our controllers.</p>

<p>```ruby
class JobsController &lt; ApplicationController
  def confirm</p>

<pre><code>@job = Job.find(params[:id])
authorize @job, :confirm? # authorization
op = Organic::JobConfirmOp.new(current_user)
op.submit!(params.merge(job_id: @job.id)) # perform action
render :show # render template
</code></pre>

<p>  end
end
```</p>

<p>An action will typically do the following:</p>

<ul>
<li>Load a resource</li>
<li>Authorize the user is allowed do do an action</li>
<li>Perform the action with an operation (other things are in place to render and error if the op fails)</li>
<li>Render a template</li>
</ul>


<p>Note that this is clearly not a typical RESTful route. We've found that becomes less important when using this pattern. When the controllers are just wiring things up and are all a 5 lines or less, it feels like there is more flexibility.</p>

<p>It probably gets summed up something like this: wherever the fat (real work) is, that should be focused. For us, it's not the controller because of service objects. The real work is 1 to 1 focused with the use case. If more was in the controllers, we'd probably be closer to the standard index, show, etc methods because of the focus concept.</p>

<h3>Sharing</h3>

<p>So we have pushed everything out closer to the user experience and away from the models. But what if something is needed in a few pieces of the experience?</p>

<p>A few ways we have done sharing:</p>

<ul>
<li>Two <code>Op</code>s can use a lower-level one or other type of class as noted above.</li>
<li>Two <code>Op</code>s can have a mixin with the shared behavior.</li>
<li>We can add a method to an applicable model. We tend to do this on simple methods that are interpreting the model data to answer a commonly-asked question or commonly-used display value.</li>
</ul>


<h3>Summary</h3>

<p>We have found that this approach provides a more maintainable and overall successful way of building Rails apps.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Architecture: Models]]></title>
    <link href="http://bleonard.github.io/blog/2017/02/24/architecture-models/"/>
    <updated>2017-02-24T00:00:00-08:00</updated>
    <id>http://bleonard.github.io/blog/2017/02/24/architecture-models</id>
    <content type="html"><![CDATA[<p>This is the first post in what I hope will be a series of articles about how we build things at <a href="https://www.taskrabbit.com">TaskRabbit</a>. Over time, we/I have internalized all kinds of lessons and patterns, but have never written them down explicitly and publicly. So let's give that a try.</p>

<p>I thought we'd start with models. That's what <a href="http://api.rubyonrails.org/classes/ActiveRecord/Base.html">Rails</a> calls database tables where each row is an instance of that model class.</p>

<p>Overall, we default to the following rules when designing the models in a system:</p>

<ul>
<li>Keep the scope small and based on decisions in the workflow</li>
<li>Use state machines to declare and lock in the valid transitions</li>
<li>Denormalize as needed to optimize use cases in the experience</li>
</ul>


<h3>Scope</h3>

<p>When designing a feature (or the whole app in its early days), you have to decide what the models represent. I'm calling that the "scope" of the model.</p>

<p>For example, most applications have a <code>User</code> model. What columns will it have? Stuff about the user, obviously. But what stuff? One of the tradeoffs to consider is <code>User</code> vs. <code>Account</code> vs. <code>Profile</code>. If you put everything about the user in the same table as the one that's pointed to in many foreign keys through the system, there will be a performance impact.</p>

<p>So we put the most commonly needed items on every screen load in the <code>User</code> model and "extra" stuff in the <code>Profile</code>.</p>

<ul>
<li><code>User</code>: authentication, name, avatar, state</li>
<li><code>Profile</code>: address, average rating, bio information</li>
</ul>


<p>There are plenty of ways to cut this up into other models and move things around, but that's what I mean about "scope" of a model.</p>

<h3>States</h3>

<p>State machines are built into the foundation of the system. Almost every model has a <code>state</code> column and an initial state. There are then valid transitions to other states.</p>

<p>For example, there is a <code>PaymentTransaction</code> model. It has an initial "pending" state that represents the time between when an invoice is submitted and when we charge the credit card. During this time, it can move to a "canceled" state if it should not happen. Or, if things go as planned, it can transition to a "settled" state. After that, if there is an issue of some sort, it would go to a "refunded" state. Notably, going from "pending" to "refunded" is <em>not</em> a valid transition.</p>

<div class="jumbotron">
<img src="http://bleonard.github.io/images/posts/architecture-models/states.png" class="bigPicture" />
</div>


<p>Creating these state and transitions preserves some sanity in the system. It's a safety check. By asserting what is possible, we can (try to) prevent things that should not be possible.</p>

<h3>Nouns and Verbs</h3>

<p>The TaskRabbit marketplace creates a job that is sent to a Tasker. The Tasker can chat with the Client and can say they will do the job. Or they can decline. If they agree, they are officially assigned to the job and make an appointment. When they complete the job, they invoice the Client for the time worked. In most cases, it's done at that point. In other cases, it is "ongoing" where they come back next week (to clean again, for example). At more or less any time, the whole thing can be canceled.</p>

<p>If given that description, you could come up with many possible model structures. They would all have a set of pros and cons, but many would work out just fine.</p>

<p>For example, you could have a <code>Job</code> model with these kinds of states: <code>invited</code>, <code>invitation_declined</code>, <code>assigned</code>, <code>appointment_made</code>, <code>invoiced</code>, <code>invoice_paid</code>, <code>canceled</code>, etc. Each would only allow the valid transitions as described above. You would also need the columns to represent the data: <code>client_id</code>, <code>tasker_id</code>, <code>appointment_at</code>, etc.</p>

<p>The main benefit of this approach is centrality. You can <code>SELECT * FROM jobs WHERE client_id = 42</code> and get all of that user's situation. Over time, however, we came to value a more decentralized approach.</p>

<p>Now, the models of our system reflect its objects and decisions that the actors make about them. Each fork in the experience has a corresponding model with a simple state machine.</p>

<p>For example, the <code>Invitation</code> model is created first to note the decision the Tasker must make. It then either transitions to <code>accepted</code> or <code>declined</code>.  If accepted, it spawns an <code>Assignment</code>. It, in turn, can move to states like <code>completed</code> or <code>ongoing</code>.</p>

<div class="jumbotron">
<img src="http://bleonard.github.io/images/posts/architecture-models/invitations.png" class="bigPicture" />
</div>


<p>There is still the the <code>Job</code> model but it contains the "description" of the work to do and its <code>id</code> ties together the decision-based models.</p>

<h3>Trade-offs</h3>

<p>Everything is pros and cons. The decentralized approach has more global complexity (more objects and interactions) but less local complexity (simpler decisions, states).</p>

<p>It seemed to be the single, monolithic state machine that doomed the single <code>Job</code> model. Everything is fine as long as that's the only path through the system. However, as soon as there is a new way for a Task to be assigned, we have a tangled web of states.</p>

<p>Not every task has the invitation pattern noted above. Some are "broadcast" to many Taskers at once and shown in a browse-able "Available Tasks" section in the their app. That's a new fork in the experience. Ongoing tasks also create a state loop of sorts.</p>

<p>These cause the single state machine to get a bit tangled up, but is more easily handled in the decentralized approach. We can make a <code>Broadcast</code> model instead of an <code>Invitation</code> one. That can have its own set of states. Success in that local state machine can also spawn an <code>Assignment</code> and everything goes on as before.</p>

<h3>Denormalization</h3>

<p>To try and get the best of both worlds, we have also aggressively embraced a variety of forms of denormalization.</p>

<p>We actively try not to do SQL <code>JOIN</code>s for simplicity and performance reasons, but that is at odds with all these little models all over the place. So we have said it's OK to have duplicate data. For example, each of these "decision" models have the <code>client_id</code>, <code>tasker_id</code>, and pricing information. It just gets passed along. This makes everything a local decision and queries very straightforward.</p>

<p>The big hole in the decentralized approach is to "get all my stuff" easily. For that we have different tactics, both of which are denormalization with use cases in mind.</p>

<p>On write to an object, we can update a central model with the current situation for that <code>Job</code>. For example, when an <code>Assignment</code> gets created, we recalculate and store data in two different tables. One for both the Tasker and the Client on what they should be seeing on their respective dashboards. Thus, the API call to "get all my stuff" uses one of those tables. That is done in the same transaction as the original write.</p>

<p>The other option is basically the same thing but for either less time-sensitive data or more complicated queries. We use a <a href="/blog/2015/04/02/queue-bus/">message bus</a> to observe changes. We then denormalize applicable data for a specific use case into a table or <a href="http://www.elastic.co">Elasticsearch</a>. For example, when an <code>Appointment</code> is created, we would update the Taskers availability schedule in the database. Updating this schedule would also trigger an update to our recommendation algorithm which uses Elasticsearch.</p>

<p>One important note: all of these denormalizations should be <a href="http://www.restapitutorial.com/lessons/idempotency.html">idempotent</a>. This allows us to recreate the whole thing from the source of truth or recover if any given event is dropped.</p>

<h3>Summary</h3>

<p>At TaskRabbit, we default to the following rules when designing the models in a system:</p>

<ul>
<li>Keep the scope small and based on decisions in the workflow</li>
<li>Use state machines to declare and lock in the valid transitions</li>
<li>Denormalize as needed to optimize use cases in the experience</li>
</ul>


<p>As always, these are just the default guidelines. In any given case, there may be a reason to deviate, but it would have to be clear why that case was special.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Developing an Amazon Alexa Skill on Rails]]></title>
    <link href="http://bleonard.github.io/blog/2016/12/02/amazon-alexa-rails/"/>
    <updated>2016-12-02T00:00:00-08:00</updated>
    <id>http://bleonard.github.io/blog/2016/12/02/amazon-alexa-rails</id>
    <content type="html"><![CDATA[<p>In March, we had a hack day at <a href="https://www.taskrabbit.com">TaskRabbit</a> and I did a demo of posting a task using a borrowed new-ish (at the time) Amazon <a href="https://www.amazon.com/echo">Echo</a> via <a href="https://developer.amazon.com/alexa">Alexa</a>. For the first time in a year, I made a new <a href="/blog/2014/02/11/rails-4-engines/">engine</a> that would handle all these new-fangled conversational UIs and bots and stuff.</p>

<p>The hack day came and went (I didn't win) and this branch was just sitting there every time I did a <code>git branch</code> command. I only have a few there. Keep it clean, people! Then I saw the Cyber Monday deals on Amazon. I decided that it had sat there long enough so I dusted it off to try and bring it to the finish line.</p>

<p>I more or less started over, of course, because that's how it goes. I thought I would document the process for anyone else on the trail.</p>

<div class="jumbotron">
  <image src="http://bleonard.github.io/images/posts/alexa/skill_store.png" class="bigPicture"/>
</div>


<h3>Alexa Sessions</h3>

<p>The <a href="https://developer.amazon.com/alexa-skills-kit">Alexa API</a> uses JSON to make requests and receive responses. Each session has a guid and (optional) user information.</p>

<p>The API has some cool session management tricks. You can <a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-interface-reference">return attributes</a> that will also get passed back on the next request. This effectively gives you "memory" of the previous parts of a conversation. I chose to not do this because I am hoping to use the same engine for other similiar interfaces. Instead I save the same stuff but to a table table using the session guid as the key. In ether case, it's important to know where you've been and what you need to move forward.</p>

<p>In our case, we want to check the box that says there has to be a linked user. Because this is checked, the Alexa App will send them through an OAuth flow on our site. So we generate a token that maps to the user in our system and Alexa stores that token in hers. Side note: it's hard to not fully personify Alexa after talking (arguing) back and forth all week.</p>

<h3>Hello World</h3>

<p>Alexa is given a single endpoint for a skill. It will POST the request to that route. So I added the line to the <code>routes.rb</code> file and sent it to a new <code>SkillsController</code>. It looks something like this:</p>

<p>```ruby
class SkillsController &lt; ::ActionController::Base
  def root</p>

<pre><code>output = AlexaRubykit::Response.new
session_end = true
output.add_speech("Hello World")
render json: output.build_response(session_end)
</code></pre>

<p>  end
end
```</p>

<!-- more -->


<p>I used the <a href="https://github.com/damianFC/alexa-rubykit">alexa_rubykit</a> gem with some <a href="https://github.com/damianFC/alexa-rubykit/pull/5">modifications</a> to parse the request and write the response.</p>

<p>So how can we get the Echo on the desk to talk to the computer? It's only 12 inches away and yet... so far! The Alexa app in the developer console has to point to a publically accessible HTTPS site. I googled around a little bit and stumbled upon <a href="https://ngrok.com">ngrok</a>. You install ngrok and run <code>ngrok http 3000</code>. This gives you a public https site that forwards to your localhost that you can put in the developer console.</p>

<h3>Alexa Intents</h3>

<p>To know what the user said involves the <a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-interaction-model-reference">intents</a> that are created in the developer console.</p>

<p>A simple example to get whatever the user said would look like this.</p>

<p>```json
{
  "intents": [</p>

<pre><code>{
  "intent": "UserInput",
  "slots": [
    {
      "name": "Generic",
      "type": "AMAZON.LITERAL"
    }
  ]
}
</code></pre>

<p>  ]
}
```</p>

<p>You also use "utterances" to give examples of this generic input.</p>

<p>There are also several other helpful intents that normalize data. For example, the user can say the date and time in many ways but Amazon can normalize that and send over a known format. Other examples include commands commands like <em>yes</em>, <em>no</em>, <em>cancel</em>, and <em>stop</em>.</p>

<p>Here are the intents I ended up with:</p>

<p>```json
{
  "intents": [</p>

<pre><code>{
  "intent": "AMAZON.YesIntent"
},
{
  "intent": "AMAZON.NoIntent"
},
{
  "intent": "AMAZON.CancelIntent"
},
{
  "intent": "AMAZON.StopIntent"
},
{
  "intent": "TaskPost",
  "slots": [
    {
      "name": "Generic",
      "type": "AMAZON.LITERAL"
    },
    {
      "name": "ScheduleDate",
      "type": "AMAZON.DATE"
    },
    {
      "name": "ScheduleTime",
      "type": "AMAZON.TIME"
    }
  ]
}
</code></pre>

<p>  ]
}
```</p>

<p>I used the <a href="https://github.com/sidoh/alexa_generator">alexa_generator</a> gem with some <a href="https://github.com/sidoh/alexa_generator/pull/1">updates</a> to declare these in a way that looks like routes. It also allows you to give examples which helps generate all the files that is needed.</p>

<p>For example, here is my <code>alexa.rb</code> file.</p>

<p>```ruby
require 'alexa_generator'</p>

<p>module Interactive
  class AlexaModel</p>

<pre><code>def self.get
  @instance
end

def self.define(&amp;block)
  @instance = AlexaGenerator::InteractionModel.build do |model|
    yield model
  end
end
</code></pre>

<p>  end
end</p>

<p>Interactive::AlexaModel.define do |model|
  model.add_intent("AMAZON.YesIntent")
  model.add_intent("AMAZON.NoIntent")
  model.add_intent("AMAZON.CancelIntent")
  model.add_intent("AMAZON.StopIntent")</p>

<p>  model.add_intent(:TaskPost) do |intent|</p>

<pre><code>intent.add_slot(:Generic, "AMAZON.LITERAL") do |slot|
  slot.add_bindings(
    'find me a handyman',
    'clean my house',
    # ... many, many things here ...
    'wait in line',
  )
end

intent.add_slot(:ScheduleDate, "AMAZON.DATE") do |slot|
  slot.add_bindings(
    'tomorrow',
    'today',
    'this friday',
    'thursday',
  )
end

intent.add_slot(:ScheduleTime, "AMAZON.TIME") do |slot|
  slot.add_bindings(
    'morning',
    'afternoon',
    'evening',
    'noon',
    'six pm',
  )
end

intent.add_utterance_template('{Generic}')
intent.add_utterance_template('{ScheduleDate} at {ScheduleTime}')
intent.add_utterance_template('{ScheduleDate} {ScheduleTime}')
intent.add_utterance_template('{ScheduleTime} {ScheduleDate}')
intent.add_utterance_template('{ScheduleDate}')
intent.add_utterance_template('{ScheduleTime}')
</code></pre>

<p>  end
end
```</p>

<p>Running a rake job I wrote will the generate the above intents json as well as the sample utterances for the developer console.</p>

<p><code>text
TaskPost {find me a handyman|Generic}
TaskPost {clean my house|Generic}
... many, many things here ...
TaskPost {wait in line|Generic}
TaskPost {ScheduleDate}
TaskPost {ScheduleDate} at {ScheduleTime}
TaskPost {ScheduleDate} {ScheduleTime}
TaskPost {ScheduleTime}
TaskPost {ScheduleTime} {ScheduleDate}
</code></p>

<h3>Simple Response</h3>

<p>A simple skill would probably have one-ish intent and few examples. It would receives those in the controller, return the response, and then end the session. We would also handle a few of the states to help the user out.</p>

<p>The controller might look like this:</p>

<p>```ruby
class SkillsController &lt; ::ActionController::Base
  def root</p>

<pre><code>input = AlexaRubykit.build_request(params)
output = AlexaRubykit::Response.new
session_end = true
message = "There was an error." # unknown thing happened

case input.type
when "LAUNCH_REQUEST"
  # user talked to our skill but did not say something matching intent
  message = "Say something see what happens."
when "INTENT_REQUEST"
  case input.name
  when "UserInput"
    # our custom, simple intent from above that user matched
    given = input.slots["Generic"].value
    message = "You said, #{given}."
  end
when "SESSION_ENDED_REQUEST"
  # it's over
  message = nil
end

output.add_speech(message) unless message.blank?
render json: output.build_response(session_end)
</code></pre>

<p>  end
end
```</p>

<h3>Conversations</h3>

<p>It all gets a bit more complicated when there is a back and forth conversation. At this point, I would say Alexa is not yet optimized for this use case.</p>

<p>For example, in our app with the shown set of intents, any one of them could come through. I could ask the user a yes/no question like "Your task is ready to book. Continue?" but the user could say "clean my house" or literally... anything. So I'd be expecting a <code>AMAZON.YesIntent</code> but get a <code>AMAZON.LITERAL</code> one. At the same time, it's very helpful to use the built in intents for their normalization capabilities. Otherwise, I'd have to do my own natural language stuff to know all the variations of dates and ways to cancel, etc.</p>

<p>So the trick of a conversation seems to be to know the state, know the related intents that are expected, and merge them together as best as possible. As noted, I store the state and the data collected in the database. In concept (in reality this is spread out over many classes), we add a case statement to the controller.</p>

<p>```ruby
class SkillsController &lt; ::ActionController::Base
  def root</p>

<pre><code>input = AlexaRubykit.build_request(params)
output = AlexaRubykit::Response.new
session_end = false # probably going to keep going
message = "There was an error." # unknown thing happened
session = Session.find_or_initialize_by(session_id: input.session.session_id)

case input.type
when "LAUNCH_REQUEST"
  # user talked to our skill but did not say something matching intent
  message = "Hi. How can we help?"
when "INTENT_REQUEST"
  case session.state
  when "selecting_category"
    category = select_category(slot_params) # uses generic
    if category
      session.category = category
      message = "What date and time?"
      session.state = "deciding_time"
    else
      message = "Sorry, missed that. Try cleaning or handyman."
    end
  when "deciding_time"
    schedule = select_schedule(slot_params) # uses date/time
    if schedule
      session.schedule = schedule
      message = "Tell us more about it"
      session.state = "adding_details"
    else
      message = "Try things like Friday at noon."
    end
  when "adding_details" # etc
  when "confirming"
    if did_confirm?(slot_params) # uses yes
      # do it!
      message = "Your task has been booked"
      session.state = "completed"
    elsif did_exit?(slot_parms)  # uses no
      session.state = "canceled"
      session_end = true
    else
      message = "Ready to confirm? Say yes or no"
    end
  when "completed"      # etc
  end
when "SESSION_ENDED_REQUEST"
  # it's over
  message = nil
  session_end = true
end

session.save!
output.add_speech(message) unless message.blank?
render json: output.build_response(session_end)
</code></pre>

<p>  end</p>

<p>  private</p>

<p>  def slot_params</p>

<pre><code># returns all the intent slots
# e.g. {"generic" =&gt; "what they said", "schedule_date" =&gt; "2016-12-05"}
return @slot_params if @slot_params

@slot_params = {}
return @slot_params unless input.type == "INTENT_REQUEST"
input.slots.each do |name, slot|
  key = name.underscore # category_noun, etc
  value = slot['value']
  @slot_params[key] = value
end

@slot_params
</code></pre>

<p>  end
end
```</p>

<p>Using this pattern, you can have a decent conversation.</p>

<h3>SDK Update Requests</h3>

<p>There are two simple things that I think would make this a much better platform.</p>

<p>The first is to be able to handle conversations better. If I could include which intents I am expecting back from the thing I just asked, everything would be 10x better.</p>

<p>The issue can be seen when the app asks for more details about the app. Basically, it wants wants to get a <code>AMAZON.Literal</code> of a few sentences and write it down. I found that if the user happens to say "tomorrow" in there somewhere, it sometimes matches the Date and that's the only data I get.</p>

<p>The issue is that what I'm interested in is specified globally and therefore does not have the context. If we could respond with expected intents or something to that effect, conversations would be much better.</p>

<p>The other feature is to be able to return links in the card. When I return <code>LinkAccount</code> card in a response, there is a call to action on the card in the Alexa App to do OAuth. I would like to return text and URL to put arbitrary things in the same spot. That way I could link the user to their task they just posted to create a more seamless experience.</p>

<h3>Summary</h3>

<p>Alexa development is fairly straightforward assuming you don't need or already have the OAuth provider bits set up. Most of the docs talk about a Java package but doing it in the Rails environment was no trouble with existing gems or parsing the json yourself.</p>

<p>It's not quite as easy for conversations but you can make it work. A few more tweaks, along with push notifications, would add a ton of value.</p>

<p>The TaskRabbit Skill is now published! Check it out.</p>
]]></content>
  </entry>
  
</feed>
